{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "text_sentiment.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VDai1999/ConcertTicketSale/blob/main/text_sentiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsFOFoy7mydf"
      },
      "source": [
        "# Import packages\n",
        "import pandas as pd\n",
        "import nltk\n",
        "nltk.download('vader_lexicon')\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer \n",
        "from statistics import mean\n",
        "import string\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "import re\n",
        "import os.path\n",
        "from os import path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72v4rAixmv-R"
      },
      "source": [
        "### Data preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CjGci9hmv-T"
      },
      "source": [
        "# load data\n",
        "data = pd.read_csv(\"Data  - Official data.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "X2SVJZERmv-U"
      },
      "source": [
        "data.head(30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "mR-NXxvFmv-X"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQm24ujUmv-Y"
      },
      "source": [
        "## Add sentiment score columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wypD2trWmv-Y"
      },
      "source": [
        "## Use Vader lexicon to generate sentiment scores\n",
        "# create the list for mean sentiment scores\n",
        "mean_neg_list = []\n",
        "mean_neu_list = []\n",
        "mean_pos_list = []\n",
        "mean_cou_list = []\n",
        "\n",
        "for i in range(0, len(data)):\n",
        "    # use video ID to get the text comments\n",
        "    name = data[\"VideoID\"][i].strip() + '.txt'\n",
        "    # if we do not have the file then set scores = 0\n",
        "    if(path.exists(name)==False):\n",
        "        mean_neg_list.append(0)\n",
        "        mean_neu_list.append(0)\n",
        "        mean_pos_list.append(0)\n",
        "        mean_cou_list.append(0)\n",
        "        continue\n",
        "    \n",
        "    ## Data Cleaning for Sentiment Analysis (without stemming)\n",
        "    corpus_cleaned = []\n",
        "    \n",
        "    # open the file \n",
        "    with open(name) as f:\n",
        "        for text in f:\n",
        "\n",
        "            tokenizer = RegexpTokenizer(r'\\w+')\n",
        "            tokens = tokenizer.tokenize(text)\n",
        "\n",
        "            filtered_words = [w for w in tokens if not w in stopwords.words('english')]\n",
        "\n",
        "            text_cleaned = \" \".join(filtered_words)\n",
        "            corpus_cleaned.append(text_cleaned)\n",
        "            \n",
        "    # if the txt file has length of 0 after cleaning then scores = 0\n",
        "    if(len(corpus_cleaned)==0):\n",
        "        mean_neg_list.append(0)\n",
        "        mean_neu_list.append(0)\n",
        "        mean_pos_list.append(0)\n",
        "        mean_cou_list.append(0)\n",
        "        continue\n",
        "    \n",
        "    # get sentiment scores\n",
        "    senScore_neg = []\n",
        "    senScore_pos = []\n",
        "    senScore_neu = []\n",
        "    senScore_cou = []\n",
        "\n",
        "    sia = SentimentIntensityAnalyzer()\n",
        "    \n",
        "    for sentence in corpus_cleaned:\n",
        "        ss = sia.polarity_scores(sentence)\n",
        "        senScore_neg.append(ss['neg'])\n",
        "        senScore_pos.append(ss['pos'])\n",
        "        senScore_neu.append(ss['neu'])\n",
        "        senScore_cou.append(ss['compound'])\n",
        "\n",
        "    # find the mean\n",
        "    mean_neg = mean(senScore_neg)\n",
        "    mean_pos = mean(senScore_pos)\n",
        "    mean_neu = mean(senScore_neu)\n",
        "    mean_cou = mean(senScore_cou)\n",
        "\n",
        "    # add mean to the list \n",
        "    mean_neg_list.append(mean_neg)\n",
        "    mean_neu_list.append(mean_neu)\n",
        "    mean_pos_list.append(mean_pos)\n",
        "    mean_cou_list.append(mean_cou)\n",
        "    \n",
        "# add the list as a new columns to data   \n",
        "data['neg_score']= mean_neg_list\n",
        "data['neu_score']= mean_neu_list\n",
        "data['pos_score']= mean_pos_list\n",
        "data['cou_score']= mean_cou_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2BE-5Akmv-Z"
      },
      "source": [
        "data.to_csv(r'Data_withSentiments.csv', index = False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}